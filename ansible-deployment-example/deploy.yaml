#! ANSIBLE_STDOUT_CALLBACK=yaml ANSIBLE_LOAD_CALLBACK_PLUGINS=1 ANSIBLE_HOST_KEY_CHECKING=False ANSIBLE_ROLES_PATH=~/Desktop/k8s/ansible-roles/ ansible-playbook -i ansible-deployment-example/inventory.yaml --tags=helm_deploy
# --tags helm_deploy

---
# ---
# -----------------------------------------------------------------
- name: Deploy k3s via external role
  hosts: all
  tags: [k3s]
  become: true

  # --- This defines the kubeconfig_root variable
  # -----------------------------------------------------------------
  # --- install k8s and configure the cluster
  # --- using https://github.com/pfisterer/k3s-dhbw-cloud-role
  roles:
    - role: k3s-dhbw-cloud-role
    
  tasks:
    # -----------------------------------------------------------------
    # --- Install helm-diff plugin
    # -----------------------------------------------------------------
    - name: Install helm diff plugin
      kubernetes.core.helm_plugin:
        plugin_path: https://github.com/databus23/helm-diff
        state: present
      tags: [prerequisites]  

    # -----------------------------------------------------------------
    # ClusterRoleBinding for ServiceAccount (rds-admin-binding)
    # -----------------------------------------------------------------
    - name: Ensure rds-admin-binding ClusterRoleBinding exists
      kubernetes.core.k8s:
        state: present
        definition:
          apiVersion: rbac.authorization.k8s.io/v1
          kind: ClusterRoleBinding
          metadata:
            name: rds-admin-binding
          subjects:
            # Grant access to the default ServiceAccount in the default namespace
            - kind: ServiceAccount
              name: default
              namespace: default
          roleRef:
            kind: ClusterRole
            name: cluster-admin # The highest level of access
            apiGroup: rbac.authorization.k8s.io
        kubeconfig: "{{ kubeconfig_root }}"

    # -----------------------------------------------------------------
    # Add helm repos
    # -----------------------------------------------------------------

    - name: Ensure all necessary Helm repositories are present
      kubernetes.core.helm_repository:
        name: "{{ item.name }}"
        repo_url: "{{ item.url }}"
        state: present
      loop:
        - { name: keel, url: https://charts.keel.sh }
        - { name: cloudnative-pg, url: https://cloudnative-pg.io/charts }

    # -----------------------------------------------------------------
    # --- Postgres Operator
    # -----------------------------------------------------------------

    - name: Install or upgrade CloudNativePG Operator
      kubernetes.core.helm:
        kubeconfig: "{{ kubeconfig_root }}"
        name: cloudnative-pg
        chart_ref: cloudnative-pg/cloudnative-pg
        release_namespace: default
        wait: true
        atomic: true
      tags: [cloud-native-pg]

    # -----------------------------------------------------------------
    # --- Keel
    # -----------------------------------------------------------------

    - name: Install or upgrade Keel
      kubernetes.core.helm:
        name: keel
        chart_ref: keel/keel
        release_namespace: default
        kubeconfig: "{{ kubeconfig_root }}"
        state: present
        wait: true
        atomic: true

    # -----------------------------------------------------------------
    # --- Clean up stuck Helm release
    # -----------------------------------------------------------------
    - name: Clean up stuck Helm release
      block:
        - name: Check Helm release status
          ansible.builtin.shell: | 
            helm status cloud-self-service -n default --kubeconfig "{{ kubeconfig_root }}"
          register: helm_status
          failed_when: false
          changed_when: "'pending' in helm_status.stderr or 'pending' in helm_status.stdout"

        - name: Remove stuck pending release
          ansible.builtin.shell: |
            # Find the highest numbered secret for this release and delete it
            SECRET=$(kubectl get secret  --kubeconfig "{{ kubeconfig_root }}" -n default -l owner=helm,name=cloud-self-service --sort-by=.metadata.creationTimestamp -o name | tail -n 1)
            kubectl delete $SECRET -n default  --kubeconfig "{{ kubeconfig_root }}"
          when: "'pending' in helm_status.stderr or 'pending' in helm_status.stdout"
      tags: [helm_deploy]


    # -----------------------------------------------------------------
    # --- Copy Helm Chart to Remote
    # -----------------------------------------------------------------
    - name: Copy Helm chart directory to remote
      ansible.posix.synchronize:
        src: "helm-chart"
        dest: "/root/"
        archive: true
        delete: true
        rsync_opts:
          - "--chown=root:root"
      tags: [helm_deploy]
      register: chart_copy

    # -----------------------------------------------------------------
    # --- Create Helm Values File from Ansible Variables
    # -----------------------------------------------------------------
    - name: Generate configuration from variable
      ansible.builtin.copy:
        content: "{{ helm_values | to_nice_yaml }}"
        dest: /root/helm-values.yaml
        owner: root
        group: root 
        mode: '0644'
      tags: [helm_deploy]
      register: values_copy

    # -----------------------------------------------------------------
    # --- Deploy with Helm Chart
    # -----------------------------------------------------------------
    - name: Deploy pdns-cloud Helm chart
      kubernetes.core.helm:
        name: dhbwcloud
        chart_ref: /root/helm-chart
        release_namespace: default
        kubeconfig: "{{ kubeconfig_root }}"
        values_files:
          - /root/helm-values.yaml
        state: present
        wait: true
        atomic: true
      register: helm_deploy_result
      tags: [helm_deploy]

    # -----------------------------------------------------------------
    # --- Enforce restart if files changed but Helm had no changes
    # -----------------------------------------------------------------
    - name: Force restart release when chart/values changed but Helm no-op
      ansible.builtin.shell: |
        set -e
        kubectl rollout restart deploy -l app.kubernetes.io/instance=dhbwcloud -n default --kubeconfig "{{ kubeconfig_root }}" || true
        kubectl rollout restart statefulset -l app.kubernetes.io/instance=dhbwcloud -n default --kubeconfig "{{ kubeconfig_root }}" || true
        kubectl rollout restart daemonset -l app.kubernetes.io/instance=dhbwcloud -n default --kubeconfig "{{ kubeconfig_root }}" || true
      when:
        - not helm_deploy_result.changed
        - chart_copy.changed or values_copy.changed
      changed_when: true
      tags: [helm_deploy]


